# Sigmoid Layer Optimization Benchmark

このリポジトリは、Deep LearningにおけるSigmoidレイヤの逆伝播（Backward Propagation）の実装効率を検証・比較するためのベンチマークです。

教科書的な「数式通りの実装（Naive）」と、フレームワークで採用される「最適化された実装（Optimized）」の計算速度を比較し、なぜ式変形が重要なのかを実証します。

## 概要

Sigmoid関数の逆伝播において、順伝播（Forward）の出力 $y$ を再利用することで、計算コストの高い指数関数 `exp` を排除できるか検証します。

### 数学的背景

Sigmoid関数:
$$y = \frac{1}{1 + \exp(-x)}$$

逆伝播の勾配 $\frac{\partial L}{\partial x}$ を求める際、以下の2通りの計算方法があります。

1.  **Naive Implementation ($x$ を使用)**
    $$\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} y^2 \exp(-x)$$

      * 毎回 `exp(-x)` の計算が必要（CPU負荷が高い）。

2.  **Optimized Implementation ($y$ を再利用)**
    $$\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} y(1 - y)$$

      * 計算済みの $y$ を使うため、四則演算のみで完結する（高速）。

## ベンチマーク結果

データサイズ $N$ を $10^4$ から $5 \times 10^6$ まで変化させ、処理時間と高速化倍率（Speedup）を計測しました。

| Size (N) | Naive (sec) | Optimized (sec) | Speedup |
| --: | --: | --: | --: |
| 10,000 | 0.00006 | 0.00001 | 8.0x |
| 50,000 | 0.00036 | 0.00003 | 10.4x |
| 100,000 | 0.00101 | 0.00007 | **13.6x** |
| 500,000 | 0.00472 | 0.00077 | 6.1x |
| 1,000,000 | 0.00878 | 0.00182 | 4.8x |
| 3,000,000 | 0.02538 | 0.00566 | 4.5x |
| 5,000,000 | 0.04631 | 0.01021 | 4.5x |


## 考察

ベンチマーク結果から、計算リソースのボトルネックが変化していることが読み取れます。

1.  **CPUバウンド領域 ($N \le 10^5$)**

      * データがCPUキャッシュに収まるサイズ。
      * メモリアクセス待ちがほぼ無いため、純粋な演算コストの差が顕著に出る。
      * `exp` 計算を回避した効果により、最大で **約13.6倍** の高速化を記録。

2.  **メモリバウンド領域 ($N \ge 10^6$)**

      * データサイズがキャッシュを超過し、メインメモリとの転送速度（帯域幅）が律速要因となる。
      * 演算速度よりもデータ転送待ちが支配的になるため、倍率は低下する。
      * それでも **約4.5倍** の高速化を維持しており、大規模な学習においてこの最適化は必須であると言える。

